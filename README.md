# linear_quantiation_for_LLMs
This repository contains a Jupyter Notebook that explores the concept of quantization for Large Language Models (LLMs) using linear quantization techniques. Quantization is a vital technique in optimizing model size and inference time, especially in resource-constrained environments.

Overview
The notebook demonstrates:

The basics of linear quantization and its application to LLMs.
How quantization impacts model performance and storage efficiency.
Steps to apply linear quantization on model weights and evaluate the quantized modelâ€™s performance.
Contents
LLM_quantization_using_linear_quantization.ipynb: The main notebook containing the implementation, explanations, and results of quantizing an LLM with linear quantization.
Getting Started
Prerequisites
To run the notebook, ensure that you have the following installed:

Python 3.7+
Jupyter Notebook
PyTorch
LLM Model Flan-T5 small
quanto library from huggingface
